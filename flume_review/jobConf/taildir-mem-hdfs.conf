a1.sources = r1
a1.channels = c1
a1.sinks = k1

# source
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /opt/module/applog/log/test.txt
a1.sources.r1.positionFile =/opt/module/flume-1.9.0/checkpoint/positionFile/taildir_position.json

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Describe the sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path =hdfs://hadoop100:9820/flumeTest/%Y-%m-%d
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.writeFormat = TEXT
a1.sinks.k1.hdfs.filePrefix = log-
# 是否按照时间滚动文件夹
a1.sinks.k1.hdfs.round = false
#多久生成一个新的文件10s
a1.sinks.k1.hdfs.rollInterval = 10
#设置每个文件的滚动大小(Byte)
a1.sinks.k1.hdfs.rollSize = 10
#文件的滚动与 Event 数量无关
a1.sinks.k1.hdfs.rollCount = 0

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1